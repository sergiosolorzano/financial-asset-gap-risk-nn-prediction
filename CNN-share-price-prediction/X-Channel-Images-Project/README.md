## Convolutional Neural Network with Bayesian hyperparameter optimization to predict next day share price from a stock price time series


<p align="center">
  <img src="https://img.shields.io/badge/Status-Work%20In%20Progress-red" alt="Work In Progress">
</p>

## Preface
This work in progress project focuses on using CNNs to predict the next-day share price of financial assets. Bayesian optimization helps narrowing the search space to evaluate hyperparameters. Unfortunately, GADF-encoded images as inputs has resulted in low prediction accuracy. These results suggest the temporal correlation between each pair of prices in the series in the form of GADF-encoded inputs is not sufficiently robust to capture the temporal structure of prices. 

<p align="center">
<img width="150" alt="star" src="https://github.com/sergiosolorzano/ai_gallery/assets/24430655/3c0b02ea-9b11-401a-b6f5-c61b69ad651b">
</p>

---------------------------------------------

## Description
We train and optimize the hyperparameters for a LeNet5-design based Convolutional Neural Network to predict the next-day share price.
We test the model with the share price time series of the Sylicon Valley Bank for the period before and after bankruptcy.
The repo runs on python and leverages available pytorch libraries.

The share prices' day Low, High, Close, Open, Adjusted Close time series are encoded into 32x32 images using [pyts Gramian angular field (GAF)](https://pyts.readthedocs.io/en/stable/auto_examples/image/plot_single_gaf.html) to obtain a temporal correlation between each pair of prices in the series.
Render of a GAF 32-day share price time series window for each feature:
<img width="1045" alt="image" src="https://github.com/sergiosolorzano/CNN-bayesian-share-price-prediction/assets/24430655/985af796-f2d1-43c2-98e9-86e9610262dc">

Render average of the above GAF images:

<img width="225" alt="image" src="https://github.com/sergiosolorzano/CNN-bayesian-share-price-prediction/assets/24430655/27cb4600-58c8-42ca-8968-d0a1b6d99586">

A stack of 32x32 images with shape (5, 491, 32, 32) would represent each of the 5 share price features' time series. Each image represents a time series window of 32 days. I slide each window by 1 day from Ti to T(len time series -33) hence obtaining 491 time series windows or GAF images for each feature.

The actual share price for each window is its the next day share price. 

## DATA
I use [Yahoo Finance](https://pypi.org/project/yfinance/) python package and historical daily share price database.

### Time series input/target data - Diagrams mostly generated by chatgptüòÅ!
As an example, for each of the 5 features (Close, High, etc) we have 524 (491+33) days of prices:

![alt text](readme_images/features_total.png)

I slide each window by 1 day starting at Ti to T(i+32) hence obtaining 32 windows each containing 491 days.

<b>Sliding Window Process For Each Feature</b>

![alt text](readme_images/features_window_boxes_sliding.png)

The time series within each window of each feature is the chunked in 32 data points, where each chunk is subsequent to the prior (i.e. there is no rolling window here). For example, for a time series of 524 data points, each window has 15 chunks (491/32=15) where 491=524-32-1 (the 1 is the last label). This produces 480 chunks per feature (32 windows * 15 chunks).

![alt text](readme_images/window_chunks.png)

The chunks are encoded into GAF images which are the inputs to the network. The actual price (target) for each chunk is the price of the next day for that chunk.

Each image represents a time series window of 32 days but has 32x32=1024 data points (pixels) because GAF obtain a temporal correlation between each pair of prices in the series - a grid of prices.

## MODEL 
A LeNet5-design based Convolutional Neural Network which includes:
+ 1 Convolution Layer 1: It's output is processed through a Rectified Linear Unit ReLU activation function and Max Pool kernel.
+ 1 Convolution Layer 2: It's output is processed through a ReLU activation function and Max Pool kernel.
+ 1 Fully Connected Layer 1: It's output is processed through a ReLU activation function.
+ 1 Fully Connected Layer 2: It's output is processed through a ReLU activation function.
+ 1 Fully Connected Layer 3: It's output is processed through a ReLU activation function.
+ filter_size_1=(2, 2) applied to Convo 1
+ filter_size_2=(2, 3) applied to Max Pool
+ filter_size_3=(2, 3) applied to Convo 2
+ stride=2 for convo layers

The model incorporates drop out regularization on the fully connected layers.

The choice of model used leverages prior work and there is no other particular reason but to test the concept.

## ACKNOWLEDGEMENTS
I thank [Yahoo Finance](https://pypi.org/project/yfinance/) for the time series data provided. I also thank for the inspiration [repo](https://github.com/ShubhamG2311/Financial-Time-Series-Forecasting), the [BayesianOptimization library s_opt module](https://github.com/bayesian-optimization/BayesianOptimization).
