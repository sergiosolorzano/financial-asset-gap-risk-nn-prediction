{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaf_images(dataset, gaf_img_sz=32, method=\"summation\", sample_range=(0,1)):\n",
    "    #print(\"len data series received:\",len(dataset),\"size\",dataset.size)\n",
    "\n",
    "    #determine num of gaf_img_szX images with gaf_img_sz datapoints\n",
    "    num_images_to_generate = floor(len(dataset) / gaf_img_sz)\n",
    "    #print(\"len dataset\",len(dataset),\"num_images_to_generate\",num_images_to_generate)\n",
    "    \n",
    "    #reshape dataset into number of images\n",
    "    dataset = dataset[:num_images_to_generate*gaf_img_sz].reshape(num_images_to_generate, gaf_img_sz)\n",
    "    #print(\"data in GAF\",dataset)\n",
    "    \n",
    "    gaf = GramianAngularField(image_size=gaf_img_sz, method=method, sample_range=sample_range)\n",
    "    gaf_images= gaf.fit_transform(dataset)\n",
    "    #print(\"gaf_image\",gaf_images.shape)\n",
    "    #print(\"returning price list\",mean_price_list)\n",
    "    \n",
    "    return gaf_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "def generate_multiple_feature_images(dataset, cols_used, image_size=32, method=\"summation\", sample_range = (0, 1)):\n",
    "    \n",
    "    feature_image_dataset_list=[[] for _ in range(len(cols_used))]\n",
    "    feature_price_dataset_list=[[] for _ in range(len(cols_used))] #=\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    feature_label_dataset_list=[] #next value for each chunk of =\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    column_idx = 0\n",
    "\n",
    "    total_single_feature_chunks = 0\n",
    "\n",
    "    for idx, column_name in enumerate(dataset.columns):\n",
    "\n",
    "      #create open,  close, high, low images. The order of \n",
    "      if column_name in cols_used:\n",
    "        temp_image_list = []\n",
    "        temp_price_list = []\n",
    "        temp_label_list = []\n",
    "        #print(\"dataset idx\", idx, \"len rows this data feature\", len(dataset[i]), \"dataset[i].shape\", dataset[i].shape, \"dataset i:\", dataset[i])\n",
    "        print(f\"Processing\",column_name)\n",
    "\n",
    "        full_feature_data = dataset[column_name].values\n",
    "        full_feature_num_samples = len(full_feature_data)\n",
    "        #print(\"full_feature_num_samples\",full_feature_num_samples)\n",
    "        #if column_name == \"Open\": print(\"total input data\",full_feature_data)\n",
    "\n",
    "        num_windows = image_size\n",
    "        #add 1 for last window label\n",
    "        adj_feature_num_samples = full_feature_num_samples - (image_size + 1)\n",
    "        #print(\"window size\",adj_feature_num_samples)\n",
    "\n",
    "        #loop by data_chunk so each chunk represents the price series that we slide by image_size\n",
    "        #print(\"full data\",full_feature_data)\n",
    "        # TODO: parallelism\n",
    "        for curr_window_index in range(num_windows):\n",
    "          \n",
    "          curr_sliding_window_data = full_feature_data[curr_window_index:adj_feature_num_samples+curr_window_index]\n",
    "          #print(f\"Curr window len {len(curr_sliding_window_data)} first value {curr_sliding_window_data[0]} next value {curr_sliding_window_data[1]} last value {curr_sliding_window_data[490]}\")\n",
    "          #if curr_window_index ==0 or curr_window_index ==1: print(f\"Curr window len {len(curr_sliding_window_data)} input: {curr_sliding_window_data[:300]}\")\n",
    "\n",
    "          target_num_chunks = floor(adj_feature_num_samples / image_size)\n",
    "          #print(f\"Target number of chunks for curr Window {column_name}\",target_num_chunks)\n",
    "          \n",
    "          for cur_chunk in range(target_num_chunks):\n",
    "            \n",
    "            if column_name == \"Open\": total_single_feature_chunks += 1\n",
    "            \n",
    "            #chunk size of image size\n",
    "            data_chunk = curr_sliding_window_data[cur_chunk*image_size:(cur_chunk*image_size)+image_size]\n",
    "            #print(\"data chunk\",cur_chunk*image_size,\"to\",(cur_chunk*image_size)+image_size,len(data_chunk))\n",
    "            #print(\"data chunk\",data_chunk)\n",
    "            #if (cur_chunk < 5 and curr_window_index==0):\n",
    "              #print(\"cur_chunk\",cur_chunk,\"input chunk\",data_chunk)\n",
    "            #append gaf image to image list. store price feature values in price list\n",
    "            gaf_images = generate_gaf_images(data_chunk, gaf_img_sz=image_size, method=method, sample_range=sample_range)\n",
    "            temp_image_list.append(gaf_images)\n",
    "            #print(\"At chunk\",cur_chunk,\"input chunk size\",len(data_chunk),\"shape gaf images\",gaf_images.shape, \"len temp image list\",len(temp_image_list))\n",
    "            \n",
    "            temp_price_list.append(curr_sliding_window_data[(cur_chunk*image_size)+image_size])\n",
    "            # if (cur_chunk < 5 and curr_window_index==0):\n",
    "            #   print(\"curr chunk\",data_chunk)\n",
    "            #   print(\"cur chunk label\",curr_sliding_window_data[(cur_chunk*image_size)+image_size])\n",
    "            # if(cur_chunk==0):\n",
    "            #   print(\"Price Data Pre-Gaf: i\", cur_chunk, \"len\",len(data_chunk), \"shape\", feature_data.shape, \"data\",data_chunk)\n",
    "            #   print(\"Image Returned: idx\", idx, \"image size\", gaf_images.size, f\"first {image_size} image vals\", gaf_images.flatten()[:image_size])\n",
    "            \n",
    "            #print(\"At chunk\",cur_chunk,\"input chunk size\",len(data_chunk),\"len price_list\",len(price_list),price_list)\n",
    "            \n",
    "            #get next single value after the chunk as label to list\n",
    "            #print(\"appending to temp label list-currcunk\",cur_chunk,\"imgsize\",image_size,\"labels\",curr_sliding_window_data[(cur_chunk*image_size)+image_size])\n",
    "            temp_label_list.append(curr_sliding_window_data[(cur_chunk*image_size)+image_size])\n",
    "            #feature_label_index_dataset_list.append(feature_data[cur_chunk + image_size + 1])\n",
    "            #print(\"chunk\",cur_chunk,\"label for\",column_name,\"price\",feature_data[cur_chunk + image_size + 1])\n",
    "            #if(column_name == \"Open\"):\n",
    "              #index position for the label of this chunk\n",
    "              #feature_label_index_dataset_list.append(cur_chunk + image_size + 1)\n",
    "              #print(\"at chunk\",cur_chunk,\"feature label list\",feature_label_index_dataset_list)\n",
    "        \n",
    "        if column_name == \"Open\": print(\"total chunks Open feature:\",total_single_feature_chunks)\n",
    "        #print(f\"Column {column_name} temp image list len to append\",len(temp_image_list))\n",
    "        feature_image_dataset_list[column_idx].append(temp_image_list)\n",
    "        #print(\"feature_image_dataset_list\",feature_image_dataset_list)\n",
    "        feature_price_dataset_list[column_idx].append(temp_price_list)\n",
    "        #print(\"price list\",price_list)\n",
    "        feature_label_dataset_list.append(temp_label_list)\n",
    "        column_idx += 1\n",
    "\n",
    "    # print(\"Final len images\",len(feature_image_dataset_list),\n",
    "    #        \"len image list index (i.e. feature) 0\",len(feature_image_dataset_list[0][0]))\n",
    "    # print(\"Final len price list\",len(feature_price_dataset_list),\n",
    "    #        \"len feature_price_dataset_list index 0 (i.e. column 0)\", len(feature_price_dataset_list[0][0]),feature_price_dataset_list)\n",
    "    # print(\"Final len labels\", len(feature_label_dataset_list),feature_label_dataset_list) # 2455=total range*5\n",
    "    \n",
    "    feature_image_dataset_list = np.array(feature_image_dataset_list) \n",
    "    #print(\"Final Shape of images before transpose:\", feature_image_dataset_list.shape, feature_image_dataset_list)\n",
    "    \n",
    "    #transpose image for CNN\n",
    "    #(5, 1, 491, 1, 32, 32)\n",
    "    feature_image_dataset_list= np.transpose(feature_image_dataset_list, (1, 3, 0, 2, 4, 5))\n",
    "    #print(\"Final Shape of images after transpose:\", feature_image_dataset_list.shape)\n",
    "\n",
    "    return feature_image_dataset_list, feature_price_dataset_list, feature_label_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_feature_image_dataset_list_f32(labels_array, images_array, image_size):\n",
    "    feature_image_dataset_list_f32 = np.array(images_array).astype(np.float32)\n",
    "    feature_image_dataset_list_f32 = feature_image_dataset_list_f32.reshape(-1, image_size, image_size)\n",
    "    #images_array = np.transpose(feature_image_dataset_list, (1, 0, 2, 3))\n",
    "\n",
    "    #scaler = MinMaxScaler()\n",
    "    scaler = StandardScaler()\n",
    "    labels_array = np.array(labels_array)\n",
    "    #print(\"labels array\",labels_array)\n",
    "    reshaped_labels_array = labels_array.reshape(-1, 1)\n",
    "    #print(\"reshaped labels array\",reshaped_labels_array)\n",
    "    labels_scaled_list_f32 = scaler.fit_transform(reshaped_labels_array).reshape(-1,).astype(np.float32)\n",
    "    #print(\"scaled labels\",labels_scaled_list_f32)\n",
    "    print(\"4D image array shape\",images_array.shape)\n",
    "    print(\"3D reshaped image array \",feature_image_dataset_list_f32.shape)\n",
    "    print(\"labels shape\",reshaped_labels_array.shape)\n",
    "    \n",
    "    return feature_image_dataset_list_f32, labels_scaled_list_f32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetTransform(normalize_ftor=0.5,resolution_x=32,resolution_y=32):\n",
    "    return transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([normalize_ftor], [normalize_ftor])\n",
    "    #transforms.Resize((resolution_x, resolution_y))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_array(input_list):\n",
    "    output_array = np.array(input_list)\n",
    "\n",
    "    return output_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
