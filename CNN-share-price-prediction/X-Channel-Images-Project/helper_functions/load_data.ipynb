{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "Device cuda:0\n",
      "cuda version 12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler, Subset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#set gpu env\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\",device)\n",
    "print(\"cuda version\",torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs #all features in one large array\n",
    "        self.labels = labels\n",
    "        self.transform = SetTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.inputs[index]\n",
    "        Y = self.labels[index]\n",
    "        return X, Y\n",
    "  \n",
    "    def prepare_ordered_dataset(self):\n",
    "        x = []\n",
    "        y = []\n",
    "        #print(\"len inputs\", len(self.inputs), \"shape\", self.inputs.shape, self.inputs.shape[0])\n",
    "        #print(\"len images 0\",len(self.inputs), \"len images 0:\",len(self.inputs[0]))\n",
    "        #print(\"images 0:\",self.inputs[0])\n",
    "        #print(\"labels\",self.labels)\n",
    "        #print(\"len labels\", len(self.labels), self.labels.shape, self.labels.shape[0])\n",
    "\n",
    "        for image_num in range(self.inputs.shape[0]):\n",
    "            #print(\"img num\",image_num,\"image\",self.inputs[image_num])\n",
    "            #print(\"len image data 0\",len(self.inputs[data_window][0]),\"shape\",self.inputs[data_window].shape)\n",
    "            #print(\"label data\",self.labels[image_num][0])\n",
    "            #print(\"imag num:\",image_num)\n",
    "            #print(\"image data at index image_num len:\",len(self.inputs[image_num]))\n",
    "            \n",
    "            self.inputs[image_num] = self.transform(self.inputs[image_num])\n",
    "            \n",
    "            x.append(np.expand_dims(self.inputs[image_num], axis=0))\n",
    "            y.append(self.labels[image_num])\n",
    "            #print(\"img num\",image_num,\"label\",self.labels[image_num])\n",
    "            #print(\"img num\",image_num,\"img\",self.inputs[image_num])\n",
    "            #print(\"img num\",image_num,\"img len\",len(self.inputs[image_num]))\n",
    "            \n",
    "        #cnn requests labels size (4,1) instead of (4)\n",
    "        y = np.expand_dims(y, axis=1) \n",
    "        #print(\"size self\",self.inputs.shape,self.labels.shape)\n",
    "        #print(\"size self\",len(x),len(y))\n",
    "        dataset = [(img, label) for img, label in zip(x, y)]\n",
    "        #print(\"type dataset returned\",type(dataset), len(dataset), len(dataset[0]), len(dataset[1]))\n",
    "        #print(\"len dataset[0][0]\",len(dataset[0][0][0][0]))\n",
    "        #print(\"len dataset[1][1]\",len(dataset[1][1]))\n",
    "        #print(\"dataset[0]\",dataset[1])\n",
    "        return dataset\n",
    "        \n",
    "        #return np.array(x),np.array(y)\n",
    "    \n",
    "    def split_data(self,dataset, batch_size, test_size, train_shuffle=False):\n",
    "        print(\"split data test size\",test_size)\n",
    "        num_samples = len(dataset)\n",
    "        #print(\"numsamples\",num_samples)\n",
    "        num_test_samples = int(test_size * num_samples)\n",
    "        num_train_samples = num_samples - num_test_samples\n",
    "        num_train_samples = num_samples - num_test_samples\n",
    "        #print(\"num_train_samples\",num_train_samples)\n",
    "        #indices = np.random.permutation(num_samples)\n",
    "        indices = np.arange(num_samples)\n",
    "        train_indices = indices[:num_train_samples]\n",
    "        test_indices = indices[num_train_samples:]\n",
    "        print(\"len train\",len(train_indices),\"len test\",len(test_indices))\n",
    "\n",
    "        #random\n",
    "        # train_sampler = SubsetRandomSampler(train_indices)\n",
    "        # test_sampler = SubsetRandomSampler(test_indices)\n",
    "        ## sequential\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        test_subset = Subset(dataset, test_indices)\n",
    "        train_sampler = SequentialSampler(train_subset)\n",
    "        test_sampler = SequentialSampler(test_subset)\n",
    "\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler,shuffle=train_shuffle)\n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "        #for e in train_loader:\n",
    "            #print(\"train loader ele\",e)\n",
    "\n",
    "        # sample_batch = next(iter(train_loader))\n",
    "        # input_shape = sample_batch[0].shape\n",
    "        # label_shape = sample_batch[1].shape\n",
    "        # print(\"input len\",len(input_shape),\"input shape\",input_shape,\"label len\",len(label_shape))\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Train_And_Test_Loaders(feature_image_dataset_list_f32,labels_scaled_list_f32, \n",
    "                                    test_size, batch_size, train_shuffle=False):\n",
    "\n",
    "    #print(\"feature_image_dataset_list_f32[0][0].shape\",feature_image_dataset_list_f32[0][0].shape, \"feature_image_dataset_list_f32[0][0].shape[0]\", feature_image_dataset_list_f32[0][0].shape[0])\n",
    "\n",
    "    #reshape for cnn\n",
    "    #reshaped_feature_image_dataset_list_f32 = np.expand_dims(feature_image_dataset_list_f32[0][0].reshape(-1, *feature_image_dataset_list_f32[0][0].shape[2:]), axis=1)\n",
    "    #print(\"feature_image_dataset_list_f32 shape\",feature_image_dataset_list_f32.shape)\n",
    "    #print(\"res\",reshaped_feature_image_dataset_list_f32.shape)\n",
    "    #print(\"labels list\",labels_scaled_list_f32)\n",
    "\n",
    "    #generate a list for images and labels\n",
    "    data_prep_class = DataPrep(feature_image_dataset_list_f32, labels_scaled_list_f32)\n",
    "\n",
    "    #print(\"feature_image_dataset_list_f32\",feature_image_dataset_list_f32[0][0].shape)\n",
    "    #print(\"labels_scaled_list_f32\",labels_scaled_list_f32.shape)\n",
    "    #returns list size all observations of all features of size 2:\n",
    "    #(image32x32,label) i.e. shape (4*480,32,32) and (4*480,1)\n",
    "    dataset = data_prep_class.prepare_ordered_dataset()\n",
    "\n",
    "    for c in range(len(dataset[0])):\n",
    "        print(f\"size labels {c}\",dataset[1][c].size)\n",
    "        print(f\"size image {c}\",dataset[0][c].shape)\n",
    "\n",
    "    train_loader, test_loader = data_prep_class.split_data(dataset, \n",
    "                                                         batch_size, test_size,\n",
    "                                                         train_shuffle)\n",
    "\n",
    "    # for c,e in enumerate(train_loader):\n",
    "    #     print(\"count\",c)\n",
    "        # print(\"type\",type(e))\n",
    "        # print(\"imga\",e[0].shape)\n",
    "        # print(\"label\",e[1].shape)\n",
    "    #returns 191 train_loaders that contain batch of 10 images32x32 and 10 labels\n",
    "    #=191*10=1910 i.e. 80% of 2400 total\n",
    "    return train_loader, test_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
